# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: ora/snapshot/v1/service.proto
# plugin: python-betterproto
# This file has been @generated

from dataclasses import dataclass
from datetime import datetime
from typing import (
    TYPE_CHECKING,
    AsyncIterable,
    AsyncIterator,
    Dict,
    Iterable,
    List,
    Optional,
    Union,
)

import betterproto
import grpclib
from betterproto.grpc.grpclib_server import ServiceBase

from ...common import v1 as __common_v1__


if TYPE_CHECKING:
    import grpclib.server
    from betterproto.grpc.grpclib_client import MetadataLike
    from grpclib.metadata import Deadline


@dataclass(eq=False, repr=False)
class ExportRequest(betterproto.Message):
    """Request for `Export`."""

    pass


@dataclass(eq=False, repr=False)
class ExportResponse(betterproto.Message):
    """Response for `Export`."""

    data: "SnapshotData" = betterproto.message_field(1)
    """The batch of data."""


@dataclass(eq=False, repr=False)
class ImportRequest(betterproto.Message):
    """Request for `Import`."""

    data: "SnapshotData" = betterproto.message_field(1)
    """The batch of data."""


@dataclass(eq=False, repr=False)
class ImportResponse(betterproto.Message):
    """Response for `Import`."""

    pass


@dataclass(eq=False, repr=False)
class SnapshotData(betterproto.Message):
    """A batch of data."""

    jobs: List["ExportedJob"] = betterproto.message_field(1)
    """The jobs in the batch."""

    executions: List["ExportedExecution"] = betterproto.message_field(2)
    """The job executions in the batch."""

    schedules: List["ExportedSchedule"] = betterproto.message_field(3)
    """The schedules in the batch."""

    job_types: List["ExportedJobType"] = betterproto.message_field(4)
    """The job types in the batch."""


@dataclass(eq=False, repr=False)
class ExportedJob(betterproto.Message):
    """All data belonging to a job."""

    id: str = betterproto.string_field(1)
    """The ID of the job."""

    schedule_id: Optional[str] = betterproto.string_field(2, optional=True)
    """The ID of the schedule that the job belongs to."""

    created_at: datetime = betterproto.message_field(3)
    """The time when the job was created."""

    job_type_id: str = betterproto.string_field(4)
    """The ID of the job type."""

    target_execution_time: datetime = betterproto.message_field(5)
    """The target execution time of the job."""

    retry_policy: "__common_v1__.JobRetryPolicy" = betterproto.message_field(6)
    """The retry policy of the job."""

    timeout_policy: "__common_v1__.JobTimeoutPolicy" = betterproto.message_field(7)
    """The timeout policy of the job."""

    labels: List["__common_v1__.JobLabel"] = betterproto.message_field(8)
    """The labels of the job."""

    marked_unschedulable_at: datetime = betterproto.message_field(9)
    """The time when the job was marked as inactive."""

    cancelled_at: datetime = betterproto.message_field(10)
    """The time when the job was cancelled."""

    input_payload_json: str = betterproto.string_field(11)
    """The input payload of the job."""

    metadata_json: Optional[str] = betterproto.string_field(12, optional=True)
    """Arbitrary metadata in JSON format."""


@dataclass(eq=False, repr=False)
class ExportedExecution(betterproto.Message):
    """All data belonging to a job execution."""

    id: str = betterproto.string_field(1)
    """The ID of the job execution."""

    job_id: str = betterproto.string_field(2)
    """The ID of the job."""

    target_execution_time: datetime = betterproto.message_field(3)
    """The target execution time of the job."""

    executor_id: Optional[str] = betterproto.string_field(4, optional=True)
    """The ID of the executor that executed the job."""

    created_at: datetime = betterproto.message_field(5)
    """The time when the job execution was created."""

    ready_at: datetime = betterproto.message_field(6)
    """
    The time when the job execution was
     ready
    """

    assigned_at: datetime = betterproto.message_field(7)
    """
    The time when the job execution was
     assigned to an executor.
    """

    started_at: datetime = betterproto.message_field(8)
    """
    The time when the job execution was
     started.
    """

    succeeded_at: datetime = betterproto.message_field(9)
    """The time when the job execution succeeded."""

    failed_at: datetime = betterproto.message_field(10)
    """The time when the job execution failed."""

    output_payload_json: Optional[str] = betterproto.string_field(11, optional=True)
    """The output payload of the job."""

    failure_reason: Optional[str] = betterproto.string_field(12, optional=True)
    """The reason why the job execution failed."""


@dataclass(eq=False, repr=False)
class ExportedSchedule(betterproto.Message):
    """All data belonging to a schedule."""

    id: str = betterproto.string_field(1)
    """The ID of the schedule."""

    created_at: datetime = betterproto.message_field(2)
    """The time when the schedule was created."""

    job_type_id: Optional[str] = betterproto.string_field(3, optional=True)
    """The ID of the job type."""

    labels: List["__common_v1__.ScheduleLabel"] = betterproto.message_field(4)
    """The labels of the schedule."""

    marked_unschedulable_at: datetime = betterproto.message_field(5)
    """The time when the schedule was marked as inactive."""

    cancelled_at: datetime = betterproto.message_field(6)
    """The time when the schedule was cancelled."""

    job_timing_policy: "__common_v1__.ScheduleJobTimingPolicy" = (
        betterproto.message_field(7)
    )
    """The scheduling policy of the schedule."""

    job_creation_policy: "__common_v1__.ScheduleJobCreationPolicy" = (
        betterproto.message_field(8)
    )
    """The new job policy of the schedule."""

    time_range: "__common_v1__.TimeRange" = betterproto.message_field(10)
    """The time range of the schedule."""

    metadata_json: Optional[str] = betterproto.string_field(11, optional=True)
    """Arbitrary metadata in JSON format."""


@dataclass(eq=False, repr=False)
class ExportedJobType(betterproto.Message):
    """All data belonging to a job type."""

    job_type: "__common_v1__.JobType" = betterproto.message_field(1)


class SnapshotServiceStub(betterproto.ServiceStub):
    async def export(
        self,
        export_request: "ExportRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> AsyncIterator[ExportResponse]:
        async for response in self._unary_stream(
            "/ora.snapshot.v1.SnapshotService/Export",
            export_request,
            ExportResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        ):
            yield response

    async def import_(
        self,
        import_request_iterator: Union[
            AsyncIterable[ImportRequest], Iterable[ImportRequest]
        ],
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> "ImportResponse":
        return await self._stream_unary(
            "/ora.snapshot.v1.SnapshotService/Import",
            import_request_iterator,
            ImportRequest,
            ImportResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )


class SnapshotServiceBase(ServiceBase):

    async def export(
        self, export_request: "ExportRequest"
    ) -> AsyncIterator[ExportResponse]:
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)
        yield ExportResponse()

    async def import_(
        self, import_request_iterator: AsyncIterator[ImportRequest]
    ) -> "ImportResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def __rpc_export(
        self, stream: "grpclib.server.Stream[ExportRequest, ExportResponse]"
    ) -> None:
        request = await stream.recv_message()
        await self._call_rpc_handler_server_stream(
            self.export,
            stream,
            request,
        )

    async def __rpc_import_(
        self, stream: "grpclib.server.Stream[ImportRequest, ImportResponse]"
    ) -> None:
        request = stream.__aiter__()
        response = await self.import_(request)
        await stream.send_message(response)

    def __mapping__(self) -> Dict[str, grpclib.const.Handler]:
        return {
            "/ora.snapshot.v1.SnapshotService/Export": grpclib.const.Handler(
                self.__rpc_export,
                grpclib.const.Cardinality.UNARY_STREAM,
                ExportRequest,
                ExportResponse,
            ),
            "/ora.snapshot.v1.SnapshotService/Import": grpclib.const.Handler(
                self.__rpc_import_,
                grpclib.const.Cardinality.STREAM_UNARY,
                ImportRequest,
                ImportResponse,
            ),
        }
