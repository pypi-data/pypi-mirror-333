# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['xcsv']

package_data = \
{'': ['*']}

install_requires = \
['pandas>=2.0.0,<3.0.0']

setup_kwargs = {
    'name': 'xcsv',
    'version': '0.6.1',
    'description': 'Package for working with extended CSV (XCSV) files',
    'long_description': "# xcsv\n\nxcsv is a package for reading and writing extended CSV files.\n\n## Extended CSV format\n\n* Extended header section of parseable atttributes, introduced by '#'.\n* Header row of variable name and units for each column.\n* Data rows.\n\n### Discussion\n\n#### Extended header section\n\n* No leading/trailing whitespace.\n* Each line introduced by a comment ('#') character.\n* Each line contains a single header item, or a single element of a multi-line list header item.\n* Key/value separator ': '.\n* Multi-line values naturally continued over to the next lines following the line introducing the key.\n* Continuation lines that contain the delimiter character in the value must be escaped by a leading delimiter.\n* Preferably use a common vocabulary for attribute name, such as [CF conventions](http://cfconventions.org/index.html).\n* Preferably include recommended attributes from [Attribute Convention for Data Discovery (ACDD)](https://wiki.esipfed.org/Attribute_Convention_for_Data_Discovery_1-3).\n* Preferably use units from [Unified Code for Units of Measure](https://ucum.org/ucum.html) and/or [Udunits](https://www.unidata.ucar.edu/software/udunits/).\n* Units in parentheses.\n* Units are automatically parsed when they appear in parentheses at the end of a line.  Hence, if you have non-units text in parentheses at the end of the line (e.g. when expanding an acronym), then ensure that the line doesn't end with a closing parenthesis to avoid the text being incorrectly parsed as units.  A '.' would suffice.\n  + This line: `# latitude: -73.86 (degree_north)` would parse correctly as a value/units dict: `'latitude': {'value': '-73.86', 'units': 'degree_north'}`.\n  + This line: `# institution: BAS (British Antarctic Survey).` would correctly avoid being parsed as a value/units dict because of the '.' as the last character.\n* Certain special keys are used to [further process the data](#automated-post-processing-of-the-data), for example the `missing_value` key.\n\n##### Example extended header section\n\n```\n# id: 1\n# title: The title\n# summary: This dataset...\n# The second summary paragraph.\n# : The third summary paragraph.  Escaped because it contains the delimiter in a URL https://dummy.domain\n# authors: A B, C D\n# institution: BAS (British Antarctic Survey).\n# latitude: -73.86 (degree_north)\n# longitude: -65.46 (degree_east)\n# elevation: 1897 (m a.s.l.)\n# [a]: 2012 not a complete year\n```\n\n#### Header row\n\n* No leading/trailing whitespace.\n* Preferably use a common vocabulary for variable name, such as [CF conventions](http://cfconventions.org/index.html).\n* Units in parentheses.\n* Optional notes in square brackets, that reference an item in the extended header section.\n\n##### Example header row\n\n```\ntime (year) [a],depth (m)\n```\n\n#### Data row\n\n* No leading/trailing whitespace.\n\n##### Example data row\n\n```\n2012,0.575\n```\n\n#### Automated post-processing of the data\n\nDepending on the presence of special keys in the extended header section, these will be used to automatically post-process the data.  To turn off this automatic behaviour, either remove or rename these keys, or set `parse_metadata=False` when reading in the data.\n\n* `missing_value`:  This is used to define those values in the data that are to be considered as missing values.  This is typically a value that is outside the domain of the data such as `-999.99`, or can be a symbolic value such as `NA`.  All such values appearing in the data will be masked, appearing as an `NA` value to pandas (i.e. `pd.isna(value) == True`).  Note that pandas itself will automatically do this for certain values regardless of this key, such as for the strings `NaN` or `NA`, or the constant `None`.\n\n#### A note on encodings\n\nThe default character set encoding is UTF-8, without a Byte Order Mark (BOM).  If an extended CSV file has a different encoding, it can either be converted to UTF-8 (by using `iconv`, for example), or the encoding can be specified when opening the file (`xcsv.File(filename, encoding=encoding)`).\n\nIf the encoding of a file is UTF-8 and it begins with a BOM, then the BOM is silently skipped.  This is necessary so that the extended header section is parsed correctly.\n\n## Install\n\nThe package can be installed from PyPI:\n\n```bash\n$ pip install xcsv\n```\n\n## Using the package\n\nThe package has a general `XCSV` class, that has a `metadata` attribute that holds the parsed contents of the extended file header section and the parsed column headers from the data table, and a `data` attribute that holds the data table (including the column headers as-is).\n\nThe `metadata` attribute is a dict, with the following general structure:\n\n```python\n{'header': {}, 'column_headers': {}}\n```\n\nand the `data` attribute is a pandas DataFrame, and so has all the features of the [pandas](https://pandas.pydata.org/docs/index.html) package.\n\nThe package also has a `Reader` class for reading an extended CSV file into an XCSV object, and similarly a `Writer` class for writing an XCSV object to a file in the extended CSV format.  In addition there is a `File` class that provides a convenient context manager for reading and writing these files.\n\n### Integrating the package with other software\n\nEven though the primary focus of the xcsv package is to produce self-describing tabular datasets, it can also read and write serialised JSON views of an XCSV object.  This is most useful when integrating XCSV data into some other software workflow.\n\nTo customise the integration when reading JSON data, any kwargs supported by `pandas.read_json()` can be passed in `data_kwargs` when calling `Reader.read_as_json()`.  Similarly when writing JSON data, any kwargs supported by `pandas.DataFrame.to_json()` can be passed in `data_kwargs` when calling `Writer.write_as_json()`.\n\nFor example, the default serialisation form is the pandas default for DataFrames (`columns`), but any serialisation form can be used by specifying the `orient` kwarg:\n\n```python\n    with open('out.json', mode='w') as fp:\n        writer = xcsv.Writer(fp=fp, xcsv=dataset)\n        writer.write_as_json(data_kwargs={'orient': 'table'})\n```\n\n### Examples\n\n#### Simple read and print\n\nRead in a file and print the contents to `stdout`.  This shows how the contents of the extended CSV file are stored in the XCSV object.  Note how multi-line values, such as `summary` here, are stored in a list.  Given the following script called, say, `simple_read.py`:\n\n```python\nimport argparse\nimport pprint\n\nimport xcsv\n\nparser = argparse.ArgumentParser()\nparser.add_argument('filename', help='filename.csv')\nargs = parser.parse_args()\n\nwith xcsv.File(args.filename) as f:\n    dataset = f.read()\n    pprint.pp(dataset.metadata)\n    print(dataset.data)\n```\n\nRunning it would produce:\n\n```bash\n$ python3 simple_read.py example.csv\n{'header': {'id': '1',\n            'title': 'The title',\n            'summary': ['This dataset...',\n                        'The second summary paragraph.',\n                        'The third summary paragraph.  Escaped because it '\n                        'contains the delimiter in a URL https://dummy.domain'],\n            'authors': 'A B, C D',\n            'institution': 'BAS (British Antarctic Survey).',\n            'latitude': {'value': '-73.86', 'units': 'degree_north'},\n            'longitude': {'value': '-65.46', 'units': 'degree_east'},\n            'elevation': {'value': '1897', 'units': 'm a.s.l.'},\n            '[a]': '2012 not a complete year'},\n 'column_headers': {'time (year) [a]': {'name': 'time',\n                                        'units': 'year',\n                                        'notes': 'a'},\n                    'depth (m)': {'name': 'depth',\n                                  'units': 'm',\n                                  'notes': None}}}\n   time (year) [a]  depth (m)\n0             2012      0.575\n1             2011      1.125\n2             2010      2.225\n```\n\n#### Simple read and print with missing values\n\nIf the above example header section included the following:\n\n```\n# missing_value: -999.99\n```\n\nand the data section looked like:\n\n```\ntime (year) [a],depth (m)\n2012,0.575\n2011,1.125\n2010,2.225\n2009,-999\n2008,999\n2007,-999.99\n2006,999.99\n2005,NA\n2004,NaN\n```\n\nRunning it would produce:\n\n```bash\n$ python3 simple_read.py missing_example.csv\n{'header': {'id': '1',\n            'title': 'The title',\n            'summary': ['This dataset...',\n                        'The second summary paragraph.',\n                        'The third summary paragraph.  Escaped because it '\n                        'contains the delimiter in a URL https://dummy.domain'],\n            'authors': 'A B, C D',\n            'institution': 'BAS (British Antarctic Survey).',\n            'latitude': {'value': '-73.86', 'units': 'degree_north'},\n            'longitude': {'value': '-65.46', 'units': 'degree_east'},\n            'elevation': {'value': '1897', 'units': 'm a.s.l.'},\n            'missing_value': '-999.99',\n            '[a]': '2012 not a complete year'},\n 'column_headers': {'time (year) [a]': {'name': 'time',\n                                        'units': 'year',\n                                        'notes': 'a'},\n                    'depth (m)': {'name': 'depth',\n                                  'units': 'm',\n                                  'notes': None}}}\n   time (year) [a]  depth (m)\n0             2012      0.575\n1             2011      1.125\n2             2010      2.225\n3             2009   -999.000\n4             2008    999.000\n5             2007        NaN\n6             2006    999.990\n7             2005        NaN\n8             2004        NaN\n```\n\nNote that the `-999.99` value has been automatically masked as a missing value (shown as `NaN` in the printed pandas DataFrame), as well as the `NA` and `NaN` strings in the original data, which pandas automatically masks itself, irrespective of the `missing_value` header item.\n\n#### Simple read and plot\n\nRead a file and plot the data:\n\n```python\nimport argparse\n\nimport matplotlib.pyplot as plt\n\nimport xcsv\n\nparser = argparse.ArgumentParser()\nparser.add_argument('filename', help='filename.csv')\nargs = parser.parse_args()\n\nwith xcsv.File(args.filename) as f:\n    dataset = f.read()\n    dataset.data.plot(x='depth (m)', y='time (year) [a]')\n    plt.show()\n```\n\n#### Simple read and write\n\nRead a file in, manipulate the data in some way, and write this modified XCSV object out to a new file:\n\n```python\nimport argparse\n\nimport xcsv\n\nparser = argparse.ArgumentParser()\nparser.add_argument('in_filename', help='in_filename.csv')\nparser.add_argument('out_filename', help='out_filename.csv')\nargs = parser.parse_args()\n\nwith xcsv.File(args.in_filename) as f:\n    dataset = f.read()\n\n# Manipulate the data...\n\nwith xcsv.File(args.out_filename, mode='w') as f:\n    f.write(xcsv=dataset)\n```\n\n#### Construct an XCSV object from data\n\nConstruct the metadata and data as python objects and combine into an XCSV object:\n\n```python\nimport pprint\n\nimport pandas as pd\n\nimport xcsv\n\n# Construct the header dict and data pandas DataFrame\nheader = {\n    'id': '123',\n    'title': 'Temperature timeseries',\n    'summary': 'This dataset comprises temperature timeseries from...',\n    'longitude': {'value': '-73.06', 'units': 'degree_east'},\n    'latitude': {'value': '-74.33', 'units': 'degree_north'}\n}\ndata = pd.DataFrame({\n    'time (day)': [1,2,3,4,5],\n    'temperature (deg_C)': [-3.5,-3.2,-2.9,-3.1,-2.8]\n})\n\n# Add the header and a placeholder for the column headers to the metadata dict\nmetadata = {'header': header, 'column_headers': {}}\n\ndataset = xcsv.XCSV(metadata=metadata, data=data)\n\n# Parse the column headers from the DataFrame and store in\n# dataset.metadata['column_headers']\ndataset.store_column_headers()\n\npprint.pp(dataset.metadata)\nprint(dataset.data)\n```\n\nRunning it would produce:\n\n```bash\n$ python3 construct_xcsv.py\n{'header': {'id': '123',\n            'title': 'Temperature timeseries',\n            'summary': 'This dataset comprises temperature timeseries from...',\n            'longitude': {'value': '-73.06', 'units': 'degree_east'},\n            'latitude': {'value': '-74.33', 'units': 'degree_north'}},\n 'column_headers': {'time (day)': {'name': 'time',\n                                   'units': 'day',\n                                   'notes': None},\n                    'temperature (deg_C)': {'name': 'temperature',\n                                            'units': 'deg_C',\n                                            'notes': None}}}\n   time (day)  temperature (deg_C)\n0           1                 -3.5\n1           2                 -3.2\n2           3                 -2.9\n3           4                 -3.1\n4           5                 -2.8\n```\n\nAs a convenience, we could use XCSV to parse value/units dicts from header item string values:\n\n```python\n    'longitude': xcsv.XCSV.parse_file_header_tokens('-73.06 (degree_east)'),\n    'latitude': xcsv.XCSV.parse_file_header_tokens('-74.33 (degree_north)')\n```\n\nInstead of printing to stdout, we could write the constructed XCSV object as an XCSV file:\n\n```python\n    with xcsv.File('out.csv', mode='w') as f:\n        f.write(dataset)\n```\n\nwhich would produce:\n\n```bash\n$ cat out.csv\n# id: 123\n# title: Temperature timeseries\n# summary: This dataset comprises temperature timeseries from...\n# longitude: -73.06 (degree_east)\n# latitude: -74.33 (degree_north)\ntime (day),temperature (deg_C)\n1,-3.5\n2,-3.2\n3,-2.9\n4,-3.1\n5,-2.8\n```\n\n",
    'author': 'Paul Breen',
    'author_email': 'pbree@bas.ac.uk',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'https://github.com/paul-breen/xcsv',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.8,<4.0',
}


setup(**setup_kwargs)
