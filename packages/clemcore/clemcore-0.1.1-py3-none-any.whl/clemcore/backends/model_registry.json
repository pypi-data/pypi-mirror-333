[
  {
      "model_name": "openchat",
      "model_id": "openchat-3.5-0106",
      "backend": "openai_compatible",
      "release_date": "2024-01-06",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "codellama-34b",
      "model_id": "codellama-34b-instruct",
      "backend": "openai_compatible",
      "release_date": "2023-08-24",
      "open_weight": true,
      "parameters": "34B"
  },
  {
      "model_name": "Llama-3-70B-Instruct-Anyscale",
      "model_id": "meta-llama/Meta-Llama-3-70B-Instruct",
      "backend": "openai_compatible",
      "release_date": "2024-04-18",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "Llama-3-70B-Together.ai",
      "model_id": "meta-llama/Llama-3-70b-chat-hf",
      "backend": "openai_compatible",
      "release_date": "2024-04-18",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "mistral-large-2411",
      "model_id": "mistralai/mistral-large-2411",
      "backend": "openai_compatible",
      "release_date": "2024-11-01",
      "open_weight": false,
      "parameters": ""
  },
  {

    "model_name": "deepseek-v3",
      "model_id": "deepseek/deepseek-chat",
      "backend": "openai_compatible",
      "release_date": "2024-12-01",
      "open_weight": true,
      "parameters": "671B"
  },
  {

    "model_name": "deepseek-r1",
      "model_id": "deepseek/deepseek-r1",
      "backend": "openai_compatible",
      "release_date": "2025-01-20",
      "open_weight": true,
      "parameters": "671B"
  },
  {
    "model_name": "qwen-max",
      "model_id": "qwen/qwen-max",
      "backend": "openai_compatible",
      "release_date": "2025-02-01",
      "open_weight": false,
      "parameters": ""
  },
  {
      "model_name": "Llama-3-8B-Instruct-Anyscale",
      "model_id": "meta-llama/Meta-Llama-3-8B-Instruct",
      "backend": "openai_compatible",
      "release_date": "2024-04-18",
      "open_weight": true,
      "parameters": "8B"
  },
  {
      "model_name": "Meta-Llama-3.1-405B-Instruct-Turbo",
      "model_id": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
      "backend": "openai_compatible",
      "release_date": "2024-07-23",
      "open_weight": true,
      "parameters": "405B"
  },
  {
      "model_name": "Mixtral-8x22B-Instruct-v0.1",
      "model_id": "mistralai/Mixtral-8x22B-Instruct-v0.1",
      "backend": "openai_compatible",
      "release_date": "2024-04-17",
      "open_weight": true,
      "parameters": "141B"
  },
  {
      "model_name": "Mixtral-8x7B-Instruct-v0.1",
      "model_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "backend": "openai_compatible",
      "release_date": "2023-12-11",
      "open_weight": true,
      "parameters": "46.7B"
  },
  {
      "model_name": "fsc-openchat-3.5-0106",
      "model_id": "openchat-3.5-0106",
      "backend": "openai_compatible",
      "release_date": "2024-01-06",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "fsc-codellama-34b-instruct",
      "model_id": "codellama-34b-instruct",
      "backend": "openai_compatible",
      "release_date": "2023-08-24",
      "open_weight": true,
      "parameters": "34B"
  },
  {
      "model_name": "gpt-4-1106-vision-preview",
      "model_id": "gpt-4-1106-vision-preview",
      "backend": "openai",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2023-11-06",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": "1.76T"
  },
  {
      "model_name": "gpt-4o-2024-05-13",
      "model_id": "gpt-4o-2024-05-13",
      "backend": "openai",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-05-13",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": "200B"
  },
  {
      "model_name": "gpt-4o-2024-08-06",
      "model_id": "gpt-4o-2024-08-06",
      "backend": "openai",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-08-06",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": "200B"
  },
  {
      "model_name": "gpt-4o-mini-2024-07-18",
      "model_id": "gpt-4o-mini-2024-07-18",
      "backend": "openai",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-07-18",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": "8B"
  },
  {
      "model_name": "gpt-4-turbo-2024-04-09",
      "model_id": "gpt-4-turbo-2024-04-09",
      "backend": "openai",
      "release_date": "2024-04-09",
      "open_weight": false,
      "parameters": "1.76T"
  },
  {
      "model_name": "gpt-4-1106-preview",
      "model_id": "gpt-4-1106-preview",
      "backend": "openai",
      "release_date": "2023-11-06",
      "open_weight": false,
      "parameters": "1.76T"
  },
  {
      "model_name": "gpt-4-0125-preview",
      "model_id": "gpt-4-0125-preview",
      "backend": "openai",
      "release_date": "2024-01-25",
      "open_weight": false,
      "parameters": "1.76T"
  },
  {
      "model_name": "o1-2024-12-17",
      "model_id": "o1-2024-12-17",
      "backend": "openai",
      "release_date": "2024-12-17",
      "open_weight": false,
      "parameters": "",
      "reasoning_model": true
  },
  {
      "model_name": "o1-preview-2024-09-12",
      "model_id": "o1-preview-2024-09-12",
      "backend": "openai",
      "release_date": "2024-09-12",
      "open_weight": false,
      "parameters": "",
      "reasoning_model": true
  },
  {
      "model_name": "o1-mini-2024-09-12",
      "model_id": "o1-mini-2024-09-12",
      "backend": "openai",
      "release_date": "2024-09-12",
      "open_weight": false,
      "parameters": "",
      "reasoning_model": true
  },
  {
    "model_name": "o3-mini-2025-01-31",
    "model_id": "o3-mini-2025-01-31",
    "backend": "openai",
    "release_date": "2025-01-31",
    "open_weight": false,
    "parameters": "",
    "reasoning_model": true
  },
  {
      "model_name": "gpt-3.5-turbo-0125",
      "model_id": "gpt-3.5-turbo-0125",
      "backend": "openai",
      "release_date": "2024-01-25",
      "open_weight": false,
      "parameters": "175B"
  },
  {
      "model_name": "gpt-4-0613",
      "model_id": "gpt-4-0613",
      "backend": "openai",
      "release_date": "2023-06-13",
      "open_weight": false,
      "parameters": "1.76T"
  },
  {
      "model_name": "gpt-4-0314",
      "model_id": "gpt-4-0314",
      "backend": "openai",
      "release_date": "2023-03-14",
      "open_weight": false,
      "parameters": "1.76T"
  },
  {
      "model_name": "gpt-3.5-turbo-1106",
      "model_id": "gpt-3.5-turbo-1106",
      "backend": "openai",
      "release_date": "2023-11-06",
      "open_weight": false,
      "parameters": "175B"
  },
  {
      "model_name": "gpt-3.5-turbo-0613",
      "model_id": "gpt-3.5-turbo-0613",
      "backend": "openai",
      "release_date": "2023-06-13",
      "open_weight": false,
      "parameters": "175B"
  },
  {
      "model_name": "mistral-medium-2312",
      "model_id": "mistral-medium-2312",
      "backend": "mistral",
      "release_date": "2023-12-01",
      "open_weight": true,
      "parameters": "",
      "estimated_parameters": "141B"
  },
  {
      "model_name": "mistral-tiny-2312",
      "model_id": "mistral-tiny-2312",
      "backend": "mistral",
      "release_date": "2023-12-01",
      "open_weight": true,
      "parameters": "",
      "estimated_parameters": "7B"
  },
  {
      "model_name": "mistral-small-2312",
      "model_id": "mistral-small-2312",
      "backend": "mistral",
      "release_date": "2023-12-01",
      "open_weight": true,
      "parameters": "",
      "estimated_parameters": "46.7B"
  },
  {
      "model_name": "mistral-large-2402",
      "model_id": "mistral-large-2402",
      "backend": "mistral",
      "release_date": "2024-02-01",
      "open_weight": true,
      "parameters": "123B"
  },
  {
      "model_name": "command",
      "model_id": "command",
      "backend": "cohere",
      "release_date": "2022-12-01",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "command-r",
      "model_id": "command-r",
      "backend": "cohere",
      "release_date": "2024-03-01",
      "open_weight": true,
      "parameters": "35B"
  },
  {
      "model_name": "command-r-plus",
      "model_id": "command-r-plus",
      "backend": "cohere",
      "release_date": "2024-04-01",
      "open_weight": true,
      "parameters": "104B"
  },
  {
      "model_name": "command-light",
      "model_id": "command-light",
      "backend": "cohere",
      "release_date": "2022-12-01",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "claude-v1.3",
      "model_id": "claude-v1.3",
      "backend": "anthropic",
      "release_date": "2023-04-18",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "claude-v1.3-100k",
      "model_id": "claude-v1.3-100k",
      "backend": "anthropic",
      "release_date": "2023-03-18",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "claude-instant-1.2",
      "model_id": "claude-instant-1.2",
      "backend": "anthropic",
      "release_date": "2023-08-09",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "claude-2",
      "model_id": "claude-2",
      "backend": "anthropic",
      "release_date": "2023-07-11",
      "open_weight": false,
      "parameters": "137B"
  },
  {
      "model_name": "claude-2.1",
      "model_id": "claude-2.1",
      "backend": "anthropic",
      "release_date": "2023-11-21",
      "open_weight": false,
      "parameters": "137B"
  },
  {
      "model_name": "claude-3-opus-20240229",
      "model_id": "claude-3-opus-20240229",
      "backend": "anthropic",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-02-29",
      "open_weight": false,
      "parameters": "2T"
  },
  {
      "model_name": "claude-3-sonnet-20240229",
      "model_id": "claude-3-sonnet-20240229",
      "backend": "anthropic",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-02-29",
      "open_weight": false,
      "parameters": "70B"
  },
  {
      "model_name": "claude-3-haiku-20240307",
      "model_id": "claude-3-haiku-20240307",
      "backend": "anthropic",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-03-07",
      "open_weight": false,
      "parameters": "20B"
  },
  {
      "model_name": "claude-3-5-sonnet-20240620",
      "model_id": "claude-3-5-sonnet-20240620",
      "backend": "anthropic",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-06-20",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "claude-3-5-haiku-20241022",
      "model_id": "claude-3-5-haiku-20241022",
      "backend": "anthropic",
      "supports_images": false,
      "support_multiple_images": false,
      "release_date": "2024-10-22",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "claude-3-5-sonnet-20241022",
      "model_id": "claude-3-5-sonnet-20241022",
      "backend": "anthropic",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-10-22",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "claude-3-7-sonnet-20250219",
      "model_id": "claude-3-7-sonnet-20250219",
      "backend": "anthropic",
      "supports_images": true,
      "support_multiple_images": true,
      "thinking_mode": true,
      "release_date": "2025-02-19",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "gemini-1.0-pro-001",
      "model_id": "gemini-1.0-pro-001",
      "backend": "google",
      "release_date": "2024-02-15",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "gemini-1.0-pro-002",
      "model_id": "gemini-1.0-pro-002",
      "backend": "google",
      "release_date": "2024-04-09",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "gemini-1.0-pro-vision-001",
      "model_id": "gemini-1.0-pro-vision-latest",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-02-15",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "gemini-1.5-flash-001",
      "model_id": "gemini-1.5-flash-001",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-05-24",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "gemini-1.5-pro-001",
      "model_id": "gemini-1.5-pro-001",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-05-24",
      "open_weight": false,
      "parameters": "1.5T"
  },
  {
      "model_name": "gemini-1.5-pro-002",
      "model_id": "gemini-1.5-pro-002",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-09-24",
      "open_weight": false,
      "parameters": "1.5T"
  },
  {
      "model_name": "gemini-1.5-flash-002",
      "model_id": "gemini-1.5-flash-002",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-09-24",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "gemini-1.5-flash-8b-001",
      "model_id": "gemini-1.5-flash-8b-001",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-10-03",
      "open_weight": false,
      "parameters": "8B"
  },
    {
      "model_name": "gemini-2.0-flash-exp",
      "model_id": "gemini-2.0-flash-exp",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-12-11",
      "open_weight": false,
      "parameters": ""
  },
  {
      "model_name": "gemini-2.0-flash-thinking-exp",
      "model_id": "gemini-2.0-flash-thinking-exp",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2025-02-01",
      "open_weight": false,
      "parameters": ""
  },
  {
      "model_name": "luminous-supreme-control",
      "model_id": "luminous-supreme-control",
      "backend": "alephalpha",
      "release_date": "2023-02-13",
      "open_weight": false,
      "parameters": "70B"
  },
  {
      "model_name": "luminous-supreme",
      "model_id": "luminous-supreme",
      "backend": "alephalpha",
      "release_date": "2022-08-15",
      "open_weight": false,
      "parameters": "70B"
  },
  {
      "model_name": "luminous-extended",
      "model_id": "luminous-extended",
      "backend": "alephalpha",
      "release_date": "2022-06-15",
      "open_weight": false,
      "parameters": "30B"
  },
  {
      "model_name": "luminous-base",
      "model_id": "luminous-base",
      "backend": "alephalpha",
      "release_date": "2022-04-14",
      "open_weight": false,
      "parameters": "13B"
  },
  {
      "model_name": "Mistral-7B-Instruct-v0.1",
      "backend": "huggingface_local",
      "huggingface_id": "mistralai/Mistral-7B-Instruct-v0.1",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-09-27",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "sheep-duck-llama-2-70b-v1.1",
      "backend": "huggingface_local",
      "huggingface_id": "Riiid/sheep-duck-llama-2-70b-v1.1",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'system' %}{{ '### System:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Assistant:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% if loop.last %}{{ '### Assistant:\\n' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-09-27",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "sheep-duck-llama-2-13b",
      "backend": "huggingface_local",
      "huggingface_id": "Riiid/sheep-duck-llama-2-13b",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'system' %}{{ '### System:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Assistant:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% if loop.last %}{{ '### Assistant:\\n' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-10-04",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "falcon-7b-instruct",
      "backend": "huggingface_local",
      "huggingface_id": "tiiuae/falcon-7b-instruct",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2023-04-25",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "falcon-40b-instruct",
      "backend": "huggingface_local",
      "huggingface_id": "tiiuae/falcon-40b-instruct",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2023-05-25",
      "open_weight": true,
      "parameters": "40B"
  },
  {
      "model_name": "oasst-sft-4-pythia-12b-epoch-3.5",
      "backend": "huggingface_local",
      "huggingface_id": "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% elif message['role'] == 'assistant' %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>' }}{% endif %}{% if loop.last %}{{ '<|assistant|>' }}{% endif %}{% endfor %}",
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2023-04-03",
      "open_weight": true,
      "parameters": "12B"
  },
  {
      "model_name": "koala-13B-HF",
      "backend": "huggingface_local",
      "huggingface_id": "TheBloke/koala-13B-HF",
      "premade_chat_template": false,
      "custom_chat_template": "{{ 'BEGINNING OF CONVERSATION: ' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% elif message['role'] == 'assistant' %}{{ 'GPT: ' + message['content'] + ' ' }}{% endif %}{% if loop.last %}{{ 'GPT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-04-07",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "Wizard-Vicuna-13B-Uncensored-HF",
      "backend": "huggingface_local",
      "huggingface_id": "TheBloke/Wizard-Vicuna-13B-Uncensored-HF",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-05-13",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "WizardLM-70b-v1.0",
      "backend": "huggingface_local",
      "huggingface_id": "WizardLM/WizardLM-70b-v1.0",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-08-09",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "WizardLM-13b-v1.2",
      "backend": "huggingface_local",
      "huggingface_id": "WizardLM/WizardLM-13b-v1.2",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-07-25",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "vicuna-7b-v1.5",
      "backend": "huggingface_local",
      "huggingface_id": "lmsys/vicuna-7b-v1.5",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-07-29",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "vicuna-13b-v1.5",
      "backend": "huggingface_local",
      "huggingface_id": "lmsys/vicuna-13b-v1.5",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-07-29",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "vicuna-33b-v1.3",
      "backend": "huggingface_local",
      "huggingface_id": "lmsys/vicuna-33b-v1.3",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-06-21",
      "open_weight": true,
      "parameters": "33B"
  },
  {
      "model_name": "gpt4all-13b-snoozy",
      "backend": "huggingface_local",
      "huggingface_id": "nomic-ai/gpt4all-13b-snoozy",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-04-24",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "CodeLlama-34b-Instruct-hf",
      "backend": "huggingface_local",
      "huggingface_id": "codellama/CodeLlama-34b-Instruct-hf",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-08-24",
      "open_weight": true,
      "parameters": "34B"
  },
  {
      "model_name": "zephyr-7b-alpha",
      "backend": "huggingface_local",
      "huggingface_id": "HuggingFaceH4/zephyr-7b-alpha",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-10-09",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "zephyr-7b-beta",
      "backend": "huggingface_local",
      "huggingface_id": "HuggingFaceH4/zephyr-7b-beta",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-10-26",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "openchat_3.5",
      "backend": "huggingface_local",
      "huggingface_id": "openchat/openchat_3.5",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|end_of_turn\\|>",
      "release_date": "2023-10-30",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Yi-34B-Chat",
      "backend": "huggingface_local",
      "huggingface_id": "01-ai/Yi-34B-Chat",
      "premade_chat_template": true,
      "slow_tokenizer": true,
      "output_split_prefix": "assistant\n",
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2023-11-22",
      "open_weight": true,
      "parameters": "34B"
  },
  {
      "model_name": "deepseek-llm-7b-chat",
      "backend": "huggingface_local",
      "huggingface_id": "deepseek-ai/deepseek-llm-7b-chat",
      "premade_chat_template": true,
      "eos_to_cull": "<\uff5cend\u2581of\u2581sentence\uff5c>",
      "release_date": "2023-11-29",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "deepseek-llm-67b-chat",
      "backend": "huggingface_local",
      "huggingface_id": "deepseek-ai/deepseek-llm-67b-chat",
      "premade_chat_template": true,
      "eos_to_cull": "<\uff5cend\u2581of\u2581sentence\uff5c>",
      "release_date": "2023-11-29",
      "open_weight": true,
      "parameters": "67B"
  },
  {
      "model_name": "tulu-2-dpo-7b",
      "backend": "huggingface_local",
      "huggingface_id": "allenai/tulu-2-dpo-7b",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-11-13",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "tulu-2-dpo-70b",
      "backend": "huggingface_local",
      "huggingface_id": "allenai/tulu-2-dpo-70b",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-11-12",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "Mixtral-8x7B-Instruct-v0.1",
      "backend": "huggingface_local",
      "huggingface_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-12-11",
      "open_weight": true,
      "parameters": "46.7B"
  },
  {
      "model_name": "SUS-Chat-34B",
      "backend": "huggingface_local",
      "huggingface_id": "SUSTech/SUS-Chat-34B",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Assistant: ' + message['content'] }}{% endif %}{% if loop.last %}{{ '### Assistant: ' }}{% endif %}{% endfor %}",
      "slow_tokenizer": true,
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2023-11-29",
      "open_weight": true,
      "parameters": "34B"
  },
  {
      "model_name": "CodeLlama-70b-Instruct-hf",
      "backend": "huggingface_local",
      "huggingface_id": "codellama/CodeLlama-70b-Instruct-hf",
      "premade_chat_template": true,
      "eos_to_cull": "<step>",
      "release_date": "2024-01-29",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "openchat-3.5-0106",
      "backend": "huggingface_local",
      "huggingface_id": "openchat/openchat-3.5-0106",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|end_of_turn\\|>",
      "release_date": "2024-01-06",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "openchat-3.5-1210",
      "backend": "huggingface_local",
      "huggingface_id": "openchat/openchat-3.5-1210",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|end_of_turn\\|>",
      "release_date": "2023-12-10",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Nous-Hermes-2-Mixtral-8x7B-DPO",
      "backend": "huggingface_local",
      "huggingface_id": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-11",
      "open_weight": true,
      "parameters": "46.7B"
  },
  {
      "model_name": "Smaug-72B-v0.1",
      "backend": "huggingface_local",
      "huggingface_id": "abacusai/Smaug-72B-v0.1",
      "premade_chat_template": false,
      "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\n' + system_message + '\n<</SYS>>\n\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}",
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2024-02-02",
      "open_weight": true,
      "parameters": "72B"
  },
  {
      "model_name": "Smaug-34B-v0.1",
      "backend": "huggingface_local",
      "huggingface_id": "abacusai/Smaug-34B-v0.1",
      "premade_chat_template": false,
      "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\n' + system_message + '\n<</SYS>>\n\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}",
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2024-01-25",
      "open_weight": true,
      "parameters": "34B"
  },
  {
      "model_name": "Qwen1.5-7B-Chat",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen1.5-7B-Chat",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-30",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Qwen1.5-72B-Chat",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen1.5-72B-Chat",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-30",
      "open_weight": true,
      "parameters": "72B"
  },
  {
      "model_name": "Swallow-70b-instruct-v0.1",
      "backend": "huggingface_local",
      "huggingface_id": "tokyotech-llm/Swallow-70b-instruct-v0.1",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-12-19",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "Phi-3-mini-128k-instruct",
      "backend": "huggingface_local",
      "huggingface_id": "microsoft/Phi-3-mini-128k-instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2024-04-22",
      "open_weight": true,
      "parameters": "3.8B"
  },
  {
      "model_name": "Starling-LM-7B-beta",
      "backend": "huggingface_local",
      "huggingface_id": "Nexusflow/Starling-LM-7B-beta",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|end_of_turn\\|>",
      "release_date": "2024-03-19",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Qwen2-7B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2-7B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-06-04",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Qwen2-72B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2-72B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-05-28",
      "open_weight": true,
      "parameters": "72B"
  },
  {
      "model_name": "Llama-3-SauerkrautLM-70b-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "VAGOsolutions/Llama-3-SauerkrautLM-70b-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-04-24",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "aya-23-8B",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "CohereForAI/aya-23-8B",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|END_OF_TURN_TOKEN\\|>",
      "release_date": "2024-05-19",
      "open_weight": true,
      "parameters": "8B"
  },
  {
      "model_name": "aya-23-35B",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "CohereForAI/aya-23-35B",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|END_OF_TURN_TOKEN\\|>",
      "release_date": "2024-05-19",
      "open_weight": true,
      "parameters": "35B"
  },
  {
      "model_name": "gemma-2-9b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/gemma-2-9b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<end_of_turn>\n*<eos>",
      "release_date": "2024-06-24",
      "open_weight": true,
      "parameters": "9B"
  },
  {
      "model_name": "gemma-2-27b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/gemma-2-27b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<end_of_turn>\n*<eos>",
      "release_date": "2024-06-24",
      "open_weight": true,
      "parameters": "27B"
  },
  {
      "model_name": "llama-2-7b-chat-hf",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "meta-llama/llama-2-7b-chat-hf",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-07-18",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "llama-2-13b-chat-hf",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "meta-llama/llama-2-13b-chat-hf",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-07-18",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "llama-2-70b-chat-hf",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "meta-llama/llama-2-70b-chat-hf",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-07-18",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "gemma-7b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/gemma-7b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<eos>",
      "release_date": "2024-02-21",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "gemma-1.1-2b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/gemma-1.1-2b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<eos>",
      "release_date": "2024-03-26",
      "open_weight": true,
      "parameters": "2B"
  },
  {
      "model_name": "gemma-1.1-7b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/gemma-1.1-7b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<eos>",
      "release_date": "2024-03-26",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "codegemma-7b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/codegemma-7b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<eos>",
      "release_date": "2024-04-09",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "recurrentgemma-2b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/recurrentgemma-2b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<eos>",
      "release_date": "2024-04-09",
      "open_weight": true,
      "parameters": "2B"
  },
  {
      "model_name": "gemma-2-2b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/gemma-2-2b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<eos>",
      "release_date": "2024-07-16",
      "open_weight": true,
      "parameters": "2B"
  },
  {
      "model_name": "Meta-Llama-3.1-8B-Instruct",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-07-23",
      "open_weight": true,
      "parameters": "8B"
  },
  {
      "model_name": "Meta-Llama-3.1-70B-Instruct",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "meta-llama/Meta-Llama-3.1-70B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-07-23",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "Mistral-Large-Instruct-2407",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "mistralai/Mistral-Large-Instruct-2407",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2024-07-24",
      "open_weight": true,
      "parameters": "123B"
  },
  {
      "model_name": "Qwen2.5-7B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2.5-7B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-07-24",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Qwen2.5-14B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2.5-14B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-07-24",
      "open_weight": true,
      "parameters": "14B"
  },
  {
      "model_name": "Qwen2.5-32B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2.5-32B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-07-24",
      "open_weight": true,
      "parameters": "32B"
  },
  {
      "model_name": "Qwen2.5-72B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2.5-72B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-07-24",
      "open_weight": true,
      "parameters": "72B"
  },
  {
      "model_name": "Llama-3.2-1B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "meta-llama/Llama-3.2-1B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-09-18",
      "open_weight": false,
      "parameters": "1B"
  },
  {
      "model_name": "Llama-3.2-3B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "meta-llama/Llama-3.2-3B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-09-18",
      "open_weight": false,
      "parameters": "3B"
  },
  {
      "model_name": "EuroLLM-1.7B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "utter-project/EuroLLM-1.7B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-09-24",
      "open_weight": true,
      "parameters": "1.7B"
  },
  {
      "model_name": "Qwen2.5-Coder-32B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-11-06",
      "open_weight": true,
      "parameters": "32B"
  },
  {
      "model_name": "Qwen2.5-Coder-14B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2.5-Coder-14B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-11-06",
      "open_weight": true,
      "parameters": "14B"
  },
  {
      "model_name": "Qwen2.5-Coder-7B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2.5-Coder-7B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-11-06",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "salamandra-7b-instruct",
      "backend": "huggingface_local",
      "huggingface_id": "BSC-LT/salamandra-7b-instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-09-30",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Llama-3.1-Nemotron-70B-Instruct-HF",
      "backend": "huggingface_local",
      "huggingface_id": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-10-12",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "TowerInstruct-13B-v0.1",
      "backend": "huggingface_local",
      "huggingface_id": "Unbabel/TowerInstruct-13B-v0.1",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-29",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "CroissantLLMChat-v0.1",
      "backend": "huggingface_local",
      "huggingface_id": "croissantllm/CroissantLLMChat-v0.1",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-24",
      "open_weight": true,
      "parameters": "1.3B"
  },
  {
      "model_name": "Llama-3.1-Tulu-3-8B",
      "backend": "huggingface_local",
      "huggingface_id": "allenai/Llama-3.1-Tulu-3-8B",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|end_of_text\\|>",
      "release_date": "2024-11-20",
      "open_weight": true,
      "parameters": "8B"
  },
  {
    "model_name": "Mistral-Small-24B-Instruct-2501",
    "backend": "huggingface_local",
    "huggingface_id": "mistralai/Mistral-Small-24B-Instruct-2501",
    "requires_api_key": true,
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "2025-01-30",
    "open_weight": true,
    "parameters": "24B"
  },
  {
    "model_name": "OLMo-2-1124-13B-Instruct",
    "backend": "huggingface_local",
    "huggingface_id": "allenai/OLMo-2-1124-13B-Instruct",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|endoftext\\|>",
    "release_date": "2024-12-18",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "phi-4",
    "backend": "huggingface_local",
    "huggingface_id": "microsoft/phi-4",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|endoftext\\|>",
    "release_date": "2024-12-11",
    "open_weight": true,
    "parameters": "14B"
    },
  {
      "model_name": "EuroLLM-9B-Instruct",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "utter-project/EuroLLM-9B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-11-28",
      "open_weight": false,
      "parameters": "9B"
  },
  {
      "model_name": "QwQ-32B-Preview",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/QwQ-32B-Preview",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-11-27",
      "open_weight": true,
      "parameters": "32B"
  },
  {
      "model_name": "aya-expanse-32b",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "CohereForAI/aya-expanse-32b",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|END_OF_TURN_TOKEN\\|>",
      "release_date": "2024-10-23",
      "open_weight": true,
      "parameters": "32B"

  },
  {
      "model_name": "Llama-3.3-70B-Instruct",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "meta-llama/Llama-3.3-70B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-12-06",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "Sky-T1-32B-Preview",
      "backend": "huggingface_local",
      "huggingface_id": "NovaSky-AI/Sky-T1-32B-Preview",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2025-01-07",
      "open_weight": true,
      "parameters": "32B"
  },
  {
      "model_name": "Qwen1.5-0.5B-Chat-GGUF-q8",
      "backend": "llamacpp",
      "huggingface_id": "Qwen/Qwen1.5-0.5B-Chat-GGUF",
      "filename": "*q8_0.gguf",
      "premade_chat_template": true,
      "bos_string": "<s>",
      "eos_string": "<|im_end|>",
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-02-03",
      "open_weight": true,
      "parameters": "0.5B"
  },
  {
      "model_name": "CapybaraHermes-2.5-Mistral-7B-GGUF-q4",
      "backend": "llamacpp",
      "huggingface_id": "TheBloke/CapybaraHermes-2.5-Mistral-7B-GGUF",
      "filename": "*Q4_0.gguf",
      "premade_chat_template": true,
      "bos_string": "<s>",
      "eos_string": "<|im_end|>",
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-31",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "CapybaraHermes-2.5-Mistral-7B-GGUF-q5",
      "backend": "llamacpp",
      "huggingface_id": "TheBloke/CapybaraHermes-2.5-Mistral-7B-GGUF",
      "filename": "*Q5_0.gguf",
      "premade_chat_template": true,
      "bos_string": "<s>",
      "eos_string": "<|im_end|>",
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-31",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "CapybaraHermes-2.5-Mistral-7B-GGUF-q5-k-s",
      "backend": "llamacpp",
      "huggingface_id": "TheBloke/CapybaraHermes-2.5-Mistral-7B-GGUF",
      "filename": "*Q5_K_S.gguf",
      "premade_chat_template": true,
      "bos_string": "<s>",
      "eos_string": "<|im_end|>",
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-31",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "EstopianMaid-13B-GGUF-q2-k",
      "backend": "llamacpp",
      "huggingface_id": "TheBloke/EstopianMaid-13B-GGUF",
      "filename": "*Q2_K.gguf",
      "premade_chat_template": false,
      "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'].strip() + '\\n\\n' %}{% else %}{% set loop_messages = messages %}{% set system_message = '' %}{% endif %}{% if system_message %}{{ bos_token + system_message }}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{bos_token + '### Instruction:\\n' + message['content'].strip() + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Response:\\n' + message['content'].strip() + eos_token + '\\n\\n' }}{% endif %}{% if loop.last and message['role'] == 'user' and add_generation_prompt %}{{ '### Response:\\n' }}{% endif %}{% endfor %}",
      "bos_string": "<s>",
      "eos_string": "</s>",
      "eos_to_cull": "</s>",
      "release_date": "2024-01-26",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "EstopianMaid-13B-GGUF-q3-k-s",
      "backend": "llamacpp",
      "huggingface_id": "TheBloke/EstopianMaid-13B-GGUF",
      "filename": "*Q3_K_S.gguf",
      "premade_chat_template": false,
      "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'].strip() + '\\n\\n' %}{% else %}{% set loop_messages = messages %}{% set system_message = '' %}{% endif %}{% if system_message %}{{ bos_token + system_message }}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{bos_token + '### Instruction:\\n' + message['content'].strip() + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Response:\\n' + message['content'].strip() + eos_token + '\\n\\n' }}{% endif %}{% if loop.last and message['role'] == 'user' and add_generation_prompt %}{{ '### Response:\\n' }}{% endif %}{% endfor %}",
      "bos_string": "<s>",
      "eos_string": "</s>",
      "eos_to_cull": "</s>",
      "release_date": "2024-01-26",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "openchat_3.5-GGUF-q5",
      "backend": "llamacpp",
      "huggingface_id": "TheBloke/openchat_3.5-GGUF",
      "filename": "*Q5_0.gguf",
      "premade_chat_template": false,
      "custom_chat_template": "{{ bos_token }}{% for message in messages %}{{ 'GPT4 Correct ' + message['role'].title() + ': ' + message['content'] + '<|end_of_turn|>'}}{% endfor %}{% if add_generation_prompt %}{{ 'GPT4 Correct Assistant:' }}{% endif %}",
      "bos_string": "<s>",
      "eos_string": "<|end_of_turn|>",
      "eos_to_cull": "<\\|end_of_turn\\|>",
      "release_date": "2023-11-02",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Meta-Llama-3-70B-Instruct-GGUF-q4",
      "backend": "llamacpp",
      "huggingface_id": "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF",
      "filename": "*Q4_K_M.gguf",
      "premade_chat_template": true,
      "bos_string": "<|begin_of_text|>",
      "eos_string": "<|eot_id|>",
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-04-18",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "Meta-Llama-3-70B-Instruct-GGUF-q8",
      "backend": "llamacpp",
      "huggingface_id": "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF",
      "filename": "*Q8_0-00001-of-00002.gguf",
      "additional_files": [
          "*Q8_0-00002-of-00002.gguf"
      ],
      "premade_chat_template": true,
      "bos_string": "<|begin_of_text|>",
      "eos_string": "<|eot_id|>",
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-04-18",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "c4ai-command-r-plus-GGUF-q4",
      "backend": "llamacpp",
      "huggingface_id": "pmysl/c4ai-command-r-plus-GGUF",
      "filename": "*Q4_K_M-00001-of-00002.gguf",
      "additional_files": [
          "*Q4_K_M-00002-of-00002.gguf"
      ],
      "premade_chat_template": true,
      "bos_string": "<BOS_TOKEN>",
      "eos_string": "<|END_OF_TURN_TOKEN|>",
      "eos_to_cull": "<\\|END_OF_TURN_TOKEN\\|>",
      "release_date": "2024-04-04",
      "open_weight": true,
      "parameters": "104B"
  },
  {
      "model_name": "c4ai-command-r-plus-GGUF-q8",
      "backend": "llamacpp",
      "huggingface_id": "pmysl/c4ai-command-r-plus-GGUF",
      "filename": "*Q8_0-00001-of-00003.gguf",
      "additional_files": [
          "*Q8_0-00002-of-00003.gguf",
          "*Q8_0-00003-of-00003.gguf"
      ],
      "premade_chat_template": true,
      "bos_string": "<BOS_TOKEN>",
      "eos_string": "<|END_OF_TURN_TOKEN|>",
      "eos_to_cull": "<\\|END_OF_TURN_TOKEN\\|>",
      "release_date": "2024-04-04",
      "open_weight": true,
      "parameters": "104B"
  },
  {
    "model_name": "bakLlava-v1-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/bakLlava-v1-hf",
    "model_class": "transformers.LlavaForConditionalGeneration",
    "model_config": {
      "low_cpu_mem_usage": true,
      "device_map": "auto",
      "torch_dtype":"auto"
    },
    "processor_class": "transformers.AutoProcessor",
    "processor_config": {},
    "prompt": "backends.multimodal_utils.generate_llava_prompt_text",
    "response": "backends.multimodal_utils.generate_llava_response",
    "output_split_prefix": "ASSISTANT:",
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-01-03",
    "open_weight": true,
    "parameters": "7B"
  },
  {
      "model_name": "llava-1.5-7b-hf",
      "backend": "huggingface_multimodal",
      "huggingface_id": "llava-hf/llava-1.5-7b-hf",
      "model_class": "transformers.LlavaForConditionalGeneration",
      "model_config": {
        "low_cpu_mem_usage": true,
        "device_map": "auto",
        "torch_dtype":"auto"
      },
      "processor_class": "transformers.AutoProcessor",
      "processor_config": {},
      "prompt": "backends.multimodal_utils.generate_llava_prompt_text",
      "response": "backends.multimodal_utils.generate_llava_response",
      "output_split_prefix": "ASSISTANT:",
      "do_sample": true,
      "supports_multiple_images": true,
      "release_date": "2024-01-03",
      "open_weight": true,
      "parameters": "7B"
  },
  {
    "model_name": "llava-1.5-13b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-1.5-13b-hf",
    "model_class": "transformers.LlavaForConditionalGeneration",
    "model_config": {
      "low_cpu_mem_usage": true,
      "device_map": "auto",
      "torch_dtype":"auto"
    },
    "processor_class": "transformers.AutoProcessor",
    "processor_config": {},
    "prompt": "backends.multimodal_utils.generate_llava_prompt_text",
    "response": "backends.multimodal_utils.generate_llava_response",
    "output_split_prefix": "ASSISTANT:",
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-01-03",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "llama3-llava-next-8b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llama3-llava-next-8b-hf",
    "model_class": "transformers.LlavaNextForConditionalGeneration",
    "model_config": {
      "low_cpu_mem_usage": true,
      "device_map": "auto",
      "torch_dtype":"auto"
    },
    "processor_class": "transformers.AutoProcessor",
    "processor_config": {},
    "prompt": "backends.multimodal_utils.generate_llava_prompt_text",
    "response": "backends.multimodal_utils.generate_llava_response",
    "output_split_prefix": "ASSISTANT:",
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-07-19",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "llava-next-110b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-next-110b-hf",
    "model_class": "transformers.LlavaNextForConditionalGeneration",
    "model_config": {
      "low_cpu_mem_usage": true,
      "device_map": "auto",
      "torch_dtype":"auto"
    },
    "processor_class": "transformers.AutoProcessor",
    "processor_config": {},
    "prompt": "backends.multimodal_utils.generate_llava_prompt_text",
    "response": "backends.multimodal_utils.generate_llava_response",
    "output_split_prefix": "ASSISTANT:",
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-07-19",
    "open_weight": true,
    "parameters": "110B"
  },
  {
    "model_name": "llava-next-72b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-next-72b-hf",
    "model_class": "transformers.LlavaNextForConditionalGeneration",
    "model_config": {
      "low_cpu_mem_usage": true,
      "device_map": "auto",
      "torch_dtype":"auto"
    },
    "processor_class": "transformers.AutoProcessor",
    "processor_config": {},
    "prompt": "backends.multimodal_utils.generate_llava_prompt_text",
    "response": "backends.multimodal_utils.generate_llava_response",
    "output_split_prefix": "ASSISTANT:",
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-07-19",
    "open_weight": true,
    "parameters": "72B"
  },
  {
    "model_name": "llava-v1.6-34b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-v1.6-34b-hf",
    "model_class": "transformers.LlavaNextForConditionalGeneration",
    "model_config": {
      "low_cpu_mem_usage": true,
      "device_map": "auto",
      "torch_dtype":"auto"
    },
    "processor_class": "transformers.AutoProcessor",
    "processor_config": {},
    "prompt": "backends.multimodal_utils.generate_llava_prompt_text",
    "response": "backends.multimodal_utils.generate_llava_response",
    "output_split_prefix": "ASSISTANT:",
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-03-17",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "llava-v1.6-mistral-7b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-v1.6-mistral-7b-hf",
    "model_class": "transformers.LlavaNextForConditionalGeneration",
    "model_config": {
      "low_cpu_mem_usage": true,
      "device_map": "auto",
      "torch_dtype":"auto"
    },
    "processor_class": "transformers.AutoProcessor",
    "processor_config": {},
    "prompt": "backends.multimodal_utils.generate_llava_prompt_text",
    "response": "backends.multimodal_utils.generate_llava_response",
    "output_split_prefix": "ASSISTANT:",
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-03-17",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "llava-v1.6-vicuna-7b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-v1.6-vicuna-7b-hf",
    "model_class": "transformers.LlavaNextForConditionalGeneration",
    "model_config": {
      "low_cpu_mem_usage": true,
      "device_map": "auto",
      "torch_dtype":"auto"
    },
    "processor_class": "transformers.AutoProcessor",
    "processor_config": {},
    "prompt": "backends.multimodal_utils.generate_llava_prompt_text",
    "response": "backends.multimodal_utils.generate_llava_response",
    "output_split_prefix": "ASSISTANT:",
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-03-17",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "llava-v1.6-vicuna-13b-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-v1.6-vicuna-13b-hf",
    "model_class": "transformers.LlavaNextForConditionalGeneration",
    "model_config": {
      "low_cpu_mem_usage": true,
      "device_map": "auto",
      "torch_dtype":"auto"
    },
    "processor_class": "transformers.AutoProcessor",
    "processor_config": {},
    "prompt": "backends.multimodal_utils.generate_llava_prompt_text",
    "response": "backends.multimodal_utils.generate_llava_response",
    "output_split_prefix": "ASSISTANT:",
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-03-17",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "llava-onevision-qwen2-7b-ov-chat-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-onevision-qwen2-7b-ov-chat-hf",
    "model_class": "transformers.LlavaOnevisionForConditionalGeneration",
    "model_config": {
      "low_cpu_mem_usage": true,
      "device_map": "auto"
    },
    "processor_class": "transformers.AutoProcessor",
    "processor_config": {},
    "prompt": "backends.multimodal_utils.generate_llava_prompt_text",
    "response": "backends.multimodal_utils.generate_llava_response",
    "output_split_prefix": "assistant:",
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-09-16",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "llava-onevision-qwen2-72b-ov-chat-hf",
    "backend": "huggingface_multimodal",
    "huggingface_id": "llava-hf/llava-onevision-qwen2-72b-ov-chat-hf",
    "model_class": "transformers.LlavaOnevisionForConditionalGeneration",
    "model_config": {
      "low_cpu_mem_usage": true,
      "device_map": "auto"
    },
    "processor_class": "transformers.AutoProcessor",
    "processor_config": {},
    "prompt": "backends.multimodal_utils.generate_llava_prompt_text",
    "response": "backends.multimodal_utils.generate_llava_response",
    "output_split_prefix": "assistant:",
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-09-16",
    "open_weight": true,
    "parameters": "72B"
  },
  {
    "model_name": "idefics-80b-instruct",
    "backend": "huggingface_multimodal",
    "huggingface_id": "HuggingFaceM4/idefics-80b-instruct",
    "model_class": "transformers.IdeficsForVisionText2Text",
    "model_config": {
      "torch_dtype":"auto",
      "device_map": "auto"
    },
    "processor_class": "transformers.AutoProcessor",
    "processor_config": {},
    "prompt": "backends.multimodal_utils.generate_idefics_prompt_text",
    "response": "backends.multimodal_utils.generate_idefics_response",
    "eos_to_cull": "<end_of_utterance>",
    "output_split_prefix": "Assistant:",
    "supports_multiple_images": true,
    "release_date": "2023-07-24",
    "open_weight": true,
    "parameters": "80B"
  },
  {
      "model_name": "idefics-9b-instruct",
      "backend": "huggingface_multimodal",
      "huggingface_id": "HuggingFaceM4/idefics-9b-instruct",
      "model_class": "transformers.IdeficsForVisionText2Text",
      "model_config": {
        "torch_dtype":"auto",
        "device_map": "auto"
      },
      "processor_class": "transformers.AutoProcessor",
      "processor_config": {},
      "prompt": "backends.multimodal_utils.generate_idefics_prompt_text",
      "response": "backends.multimodal_utils.generate_idefics_response",
      "eos_to_cull": "<end_of_utterance>",
      "output_split_prefix": "Assistant:",
      "supports_multiple_images": true,
      "release_date": "2023-07-24",
      "open_weight": true,
      "parameters": "9B"
  },
  {
    "model_name": "InternVL2-Llama3-76B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-Llama3-76B",
    "model_class": "transformers.AutoModel",
    "model_config": {
        "torch_dtype": "auto",
        "load_in_8bit": true,
        "low_cpu_mem_usage": true,
        "use_flash_attn": true,
        "device_map": "backends.multimodal_utils.split_model"
    },
    "processor_class": "transformers.AutoTokenizer",
    "processor_config": {
        "use_fast": false
    },
    "prompt": "backends.multimodal_utils.generate_internvl2_prompt_text",
    "response": "backends.multimodal_utils.generate_internvl2_response",
    "trust_remote_code": true,
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-07-15",
    "open_weight": true,
    "parameters": "76B"
  },
  {
    "model_name": "InternVL2-40B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-40B",
    "model_class": "transformers.AutoModel",
    "model_config": {
        "torch_dtype": "auto",
        "load_in_8bit": true,
        "low_cpu_mem_usage": true,
        "use_flash_attn": true,
        "device_map": "backends.multimodal_utils.split_model"
    },
    "processor_class": "transformers.AutoTokenizer",
    "processor_config": {
        "use_fast": false
    },
    "prompt": "backends.multimodal_utils.generate_internvl2_prompt_text",
    "response": "backends.multimodal_utils.generate_internvl2_response",
    "trust_remote_code": true,
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-07-15",
    "open_weight": true,
    "parameters": "40B"
  },
  {
    "model_name": "InternVL2-26B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-26B",
    "model_class": "transformers.AutoModel",
    "model_config": {
        "torch_dtype": "auto",
        "load_in_8bit": true,
        "low_cpu_mem_usage": true,
        "use_flash_attn": true,
        "device_map": "backends.multimodal_utils.split_model"
    },
    "processor_class": "transformers.AutoTokenizer",
    "processor_config": {
        "use_fast": false
    },
    "prompt": "backends.multimodal_utils.generate_internvl2_prompt_text",
    "response": "backends.multimodal_utils.generate_internvl2_response",
    "trust_remote_code": true,
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-07-15",
    "open_weight": true,
    "parameters": "26B"
  },
  {
    "model_name": "InternVL2-8B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-8B",
    "model_class": "transformers.AutoModel",
    "model_config": {
        "torch_dtype": "auto",
        "load_in_8bit": true,
        "low_cpu_mem_usage": true,
        "use_flash_attn": true,
        "device_map": "backends.multimodal_utils.split_model"
    },
    "processor_class": "transformers.AutoTokenizer",
    "processor_config": {
        "use_fast": false
    },
    "prompt": "backends.multimodal_utils.generate_internvl2_prompt_text",
    "response": "backends.multimodal_utils.generate_internvl2_response",
    "trust_remote_code": true,
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-07-15",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "internlm-xcomposer2d5-7b",
    "backend": "huggingface_multimodal",
    "huggingface_id": "internlm/internlm-xcomposer2d5-7b",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.intern_utils.InternlmMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "output_split_prefix": "",
    "not_distributed": true,
    "release_date": "2024-07-02",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Idefics3-8B-Llama3",
    "backend": "huggingface_multimodal",
    "huggingface_id": "HuggingFaceM4/Idefics3-8B-Llama3",
    "model_class": "transformers.AutoModelForVision2Seq",
    "model_config": {
        "torch_dtype": "auto",
        "device_map": "auto"
    },
    "processor_class": "transformers.AutoProcessor",
    "processor_config": {},
    "prompt": "backends.multimodal_utils.generate_llava_prompt_text",
    "response": "backends.multimodal_utils.generate_llava_response",
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "output_split_prefix": "Assistant:",
    "release_date": "2024-08-05",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "dolphin-vision-72b",
    "backend": "huggingface_multimodal",
    "huggingface_id": "cognitivecomputations/dolphin-vision-72b",
    "automodel_type": "transformers.AutoModelForCausalLM",
    "model_class": "backends.multimodal_utils.dolphin_utils.DolphinMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "output_split_prefix": "",
    "low_cpu_mem_usage": true,
    "release_date": "2024-06-28",
    "open_weight": true,
    "parameters": "72B"
  },
  {
    "model_name": "Phi-3.5-vision-instruct",
    "backend": "huggingface_multimodal",
    "huggingface_id": "microsoft/Phi-3.5-vision-instruct",
    "automodel_type": "transformers.AutoModelForCausalLM",
    "model_class": "backends.multimodal_utils.phi_utils.PhiMLLM",
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "output_split_prefix": "",
    "low_cpu_mem_usage": true,
    "release_date": "2024-08-17",
    "open_weight": true,
    "parameters": "4B"
  },
  {
    "model_name": "Pixtral-12B-2409",
    "backend": "huggingface_multimodal",
    "huggingface_id": "mistralai/Pixtral-12B-2409",
    "automodel_type": "vllm.LLM",
    "model_class": "backends.multimodal_utils.pixtral_utils.PixtralMLLM",
    "supports_multiple_images": true,
    "trust_remote_code": false,
    "output_split_prefix": "",
    "low_cpu_mem_usage": true,
    "release_date": "2024-09-11",
    "open_weight": true,
    "parameters": "12B",
    "use_vllm": true,
    "tokenizer_mode": "mistral",
    "vllm_context": 8192
  },
  {
    "model_name": "Meta-Llama-3.1-70B-Instruct-FP8-neuralmagic-1gpu",
    "backend": "vllm",
    "huggingface_id": "neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8",
    "number_gpus": 1,
    "premade_chat_template": true,
    "eos_to_cull": "<\\|eot_id\\|>",
    "release_date": "2023-07-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Meta-Llama-3.1-70B-Instruct-FP8-neuralmagic-1gpu-4k",
    "backend": "vllm",
    "huggingface_id": "neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8",
    "number_gpus": 1,
    "context_limit": 4096,
    "premade_chat_template": true,
    "eos_to_cull": "<\\|eot_id\\|>",
    "release_date": "2023-07-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Meta-Llama-3.1-70B-Instruct-FP8-neuralmagic-1gpu-8k",
    "backend": "vllm",
    "huggingface_id": "neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8",
    "number_gpus": 1,
    "context_limit": 8192,
    "premade_chat_template": true,
    "eos_to_cull": "<\\|eot_id\\|>",
    "release_date": "2023-07-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Meta-Llama-3.1-70B-Instruct-FP8-neuralmagic-2gpu",
    "backend": "vllm",
    "huggingface_id": "neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8",
    "number_gpus": 2,
    "premade_chat_template": true,
    "eos_to_cull": "<\\|eot_id\\|>",
    "release_date": "2023-07-23",
    "open_weight": true,
    "parameters": "70B"
  }
]