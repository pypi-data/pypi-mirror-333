{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drift Watch Monitoring Server\n",
    "\n",
    "Drift Watch monitoring server is a stand-alone HTTP server that serves multiple REST API endpoints for storing experiments and drifts. While Drift Watch can be used in local environment, for starters it is recommended to use one of the available online endpoints. This way you can easily share your results with your team members and access them from anywhere:\n",
    "\n",
    "**Collaboration**: Multiple users can create experiment in the same endpoints where to log drifts.\n",
    "\n",
    "**Sharing Results**: The monitoring server also serves as monitoring interface, where members can easily explore each other’s results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging to a Monitoring Server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you started the tracking server, you can connect your local clients by set the **DRIFT_MONITOR_URL** environment variable to the server’s URI, along with its scheme and port (for example, http://localhost:5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DRIFT_MONITOR_URL\"] = \"https://drift-watch.dev.ai4eosc.eu\"\n",
    "os.environ[\"DRIFT_MONITOR_MYTOKEN\"] = \"token_from_mytoken.data.kit.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from drift_monitor import DriftMonitor, new_experiment, register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register to the service in case you did not do it before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "register(accept_terms=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your detector methods. In this example, for the aim os simplicity, we mock detectors where a tuple (detection, features) is returned. The detection is a boolean indicating if the detector found an anomaly or not. The features is a dictionary with the features used in the detector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector_example(*args, **kwds) -> tuple[bool, dict]:\n",
    "    return True, {\"feature1\": 0.05, \"feature2\": 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open a DriftMonitor context and call the detectors. The DriftMonitor will store the results in a dictionary with the detector names as keys and the tuple (detection, features) as values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experiment(name='experiment_e07360f4-2d96-4cec-b436-720451b75452', description='Test experiment example', public=True, permissions=[{'entity': '4f8e73b1-ad6c-46af-8415-0ce39d74e9c0', 'level': 'Manage'}])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = f\"experiment_{uuid4()}\"\n",
    "description = \"Test experiment example\"\n",
    "new_experiment(experiment_name, description, public=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "tags = [\"concept_drift\", \"Early-DDM\", \"example_docs\"]\n",
    "with DriftMonitor(experiment_name, \"model_1\", tags) as monitor:\n",
    "    detected, detection_parameters = detector_example()\n",
    "    monitor(detected, detection_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the context is closed, the DriftMonitor will send the results to the API with status \"Completed\". If and exception occurs, the DriftMonitor will catch the exception, send the results with status \"Failed\" and re-raise the exception.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
