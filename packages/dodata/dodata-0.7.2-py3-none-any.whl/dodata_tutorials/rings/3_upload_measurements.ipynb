{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Upload Measurements and run analysis\n",
    "\n",
    "Now you will post your measurement data and analysis to the database via the DoData app.\n",
    "\n",
    "**If you are running the tutorials in DoLab, the following instructions are not necessary and you can skip directly to the next cell.**\n",
    "\n",
    "You will need to authenticate to the database with your username and password. To make this easy, you can create a file called `.env` in this folder and complete it with your organization's URL and authentication information as follows:\n",
    "\n",
    "```bash\n",
    "dodata_url=https://animal.doplaydo.com\n",
    "dodata_user=demo\n",
    "dodata_password=yours\n",
    "dodata_db=animal.dodata.db.doplaydo.com\n",
    "dodata_db_user=full_access\n",
    "dodata_db_password=yours\n",
    "\n",
    "```\n",
    "\n",
    "If you haven't defined a `.env` file or saved your credentials to your environment variables, you will be prompted for your credentials now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from httpx import HTTPStatusError\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import doplaydo.dodata as dd\n",
    "\n",
    "username = getpass.getuser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Let's now create a project. \n",
    "\n",
    "In normal circumstances, everyone will be sharing and contributing to a project. In this demo, however, we want to *keep your project separate* from other users for clarity, so we will append your username to the project id. This way you can also safely delete and recreate projects without creating issues for others. If you prefer though, you can change the `PROJECT_ID` to anything you like. Just be sure to update it in the subsequent notebooks of this tutorial as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = f\"rings-{username}-{platform.node()}\"\n",
    "MEASUREMENTS_PATH = Path(\"6d4c615ff105/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "If you've been running this demo multiple times, you might already have one with the same name. Let's delete it so you can start fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(dd.project.delete(project_id=PROJECT_ID).text)\n",
    "except HTTPStatusError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## New project\n",
    "\n",
    "You can create the project, upload the design manifest, and upload the wafer definitions through the Webapp as well as programmatically using this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Upload Project\n",
    "\n",
    "You can create a new project and extract all cells & devices below for the `RidgeLoss` and `RibLoss`\n",
    "\n",
    "The expressions are regex expressions. For intro and testing your regexes you can check out [regex101](https://regex101.com)\n",
    "\n",
    "To only extract top cells set `max_hierarchy_lvl=-1` and `min_hierarchy_lvl=-1`\n",
    "\n",
    "To disable extraction use a max_hierarchy_lvl < min_hierarchy_lvl\n",
    "\n",
    "Whitelists take precedence over blacklists, so if you define both, it uses only the whitelist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_extraction = [\n",
    "    dd.project.Extraction(\n",
    "        cell_id=\"rings\",\n",
    "        cell_white_list=[\"^RingDouble\"],\n",
    "        min_hierarchy_lvl=0,\n",
    "        max_hierarchy_lvl=0,\n",
    "    )\n",
    "]\n",
    "\n",
    "dd.project.create(\n",
    "    project_id=PROJECT_ID,\n",
    "    eda_file=\"test_chip.gds\",\n",
    "    lyp_file=\"generic.lyp\",\n",
    "    cell_extractions=cell_extraction,\n",
    ").text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Upload Design Manifest\n",
    "\n",
    "The design manifest is a CSV file that includes all the cell names, the cell settings, a list of analysis to trigger, and a list of settings for each analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = pd.read_csv(\"design_manifest.csv\")\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "As you don't have an analysis defined yet you need to drop the columns that allow you to run automated analysis on measurement upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = dm.drop(columns=[\"analysis\", \"analysis_parameters\"])\n",
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.to_csv(\"design_manifest_without_analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.project.upload_design_manifest(\n",
    "    project_id=PROJECT_ID, filepath=\"design_manifest_without_analysis.csv\"\n",
    ").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.project.download_design_manifest(\n",
    "    project_id=PROJECT_ID, filepath=\"design_manifest_downloaded.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Upload Wafer Definitions\n",
    "\n",
    "The wafer definition is a JSON file where you can define the wafer names and die names and location for each wafer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.project.upload_wafer_definitions(\n",
    "    project_id=PROJECT_ID, filepath=\"wafer_definitions.json\"\n",
    ").text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Upload data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Your Tester can output the data in JSON files. It does not need to be Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "You can get all paths which have measurement data within the test path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = list(MEASUREMENTS_PATH.glob(\"**/data.json\"))\n",
    "print(data_files[0].parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    " You should define a plotting per measurement type in python. Your plots can evolve over time even for the same measurement type.\n",
    "\n",
    "Required:\n",
    "\n",
    "```yaml\n",
    "- x_name (str): x-axis name\n",
    "- y_name (str): y-axis name\n",
    "- x_col (str): x-column to plot\n",
    "- y_col (list[str]): y-column(s) to plot; can be multiple\n",
    "```\n",
    "\n",
    "\n",
    "Optional:\n",
    "```yaml\n",
    "\n",
    "- scatter (bool): whether to plot as scatter as opposed to line traces\n",
    "- x_units (str): x-axis units\n",
    "- y_units (str): y-axis units\n",
    "- x_log_axis (bool): whether to plot the x-axis on log scale\n",
    "- y_log_axis (bool): whether to plot the y-axis on log scale\n",
    "- x_limits (list[int, int]): clip x-axis data using these limits as bounds (example: [10, 100])\n",
    "- y_limits (list[int, int]): clip y-axis data using these limits as bounds (example: [20, 100])\n",
    "- sort_by (dict[str, bool]): columns to sort data before plotting. Boolean specifies whether to sort each column in ascending order.\n",
    "                             (example: {\"wavelegths\": True, \"optical_power\": False})\n",
    "- grouping (dict[str, int]): columns to group data before plotting. Integer specifies decimal places to round each column.\n",
    "                             Different series will be plotted for unique combinations of x column, y column(s), and rounded column values.\n",
    "                             (example: {\"port\": 1, \"attenuation\": 2})\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_measurement_type = dd.api.device_data.PlottingKwargs(\n",
    "    x_name=\"wavelength\",\n",
    "    y_name=\"output_power\",\n",
    "    x_col=\"wavelength\",\n",
    "    y_col=[\"output_power\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Upload measurements\n",
    "\n",
    "You can now upload measurement data.\n",
    "\n",
    "This is a bare bones example, in a production setting, you can also add validation, logging, and error handling to ensure a smooth operation.\n",
    "\n",
    "Every measurement you upload will trigger all the analysis that you defined in the design manifest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_THREADS = 1 if \"127\" in dd.settings.dodata_url else dd.settings.n_threads\n",
    "wafer_set = set()\n",
    "die_set = set()\n",
    "NUMBER_OF_THREADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUMBER_OF_THREADS == 1:\n",
    "    for path in tqdm(data_files):\n",
    "        wafer_id = path.parts[0]\n",
    "        die_x, die_y = path.parts[1].split(\"_\")\n",
    "\n",
    "        r = dd.api.device_data.upload(\n",
    "            file=path,\n",
    "            project_id=PROJECT_ID,\n",
    "            wafer_id=wafer_id,\n",
    "            die_x=die_x,\n",
    "            die_y=die_y,\n",
    "            device_id=path.parts[2],\n",
    "            data_type=\"measurement\",\n",
    "            plotting_kwargs=spectrum_measurement_type,\n",
    "        )\n",
    "        wafer_set.add(wafer_id)\n",
    "        die_set.add(path.parts[2])\n",
    "        r.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = list(MEASUREMENTS_PATH.glob(\"**/data.json\"))\n",
    "project_ids = []\n",
    "device_ids = []\n",
    "die_ids = []\n",
    "die_xs = []\n",
    "die_ys = []\n",
    "wafer_ids = []\n",
    "plotting_kwargs = []\n",
    "data_types = []\n",
    "\n",
    "for path in data_files:\n",
    "    device_id = path.parts[2]\n",
    "    die_id = path.parts[1]\n",
    "    die_x, die_y = die_id.split(\"_\")\n",
    "    wafer_id = path.parts[0]\n",
    "\n",
    "    device_ids.append(device_id)\n",
    "    die_ids.append(die_id)\n",
    "    die_xs.append(die_x)\n",
    "    die_ys.append(die_y)\n",
    "    die_set.add(die_id)\n",
    "    wafer_ids.append(wafer_id)\n",
    "    plotting_kwargs.append(spectrum_measurement_type)\n",
    "    project_ids.append(PROJECT_ID)\n",
    "    data_types.append(\"measurement\")\n",
    "    wafer_set.add(wafer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUMBER_OF_THREADS > 1:\n",
    "    dd.device_data.upload_multi(\n",
    "        files=data_files,\n",
    "        project_ids=project_ids,\n",
    "        wafer_ids=wafer_ids,\n",
    "        die_xs=die_xs,\n",
    "        die_ys=die_ys,\n",
    "        device_ids=device_ids,\n",
    "        data_types=data_types,\n",
    "        plotting_kwargs=plotting_kwargs,\n",
    "        progress_bar=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "You can run analysis at 3 different levels. For example to extract:\n",
    "\n",
    "1. Device: averaged power envelope over certain number of samples.\n",
    "2. Die: fit the propagation loss as a function of length.\n",
    "3. Wafer: Define the Upper and Lower Spec limits for Known Good Die (KGD)\n",
    "\n",
    "![](https://i.imgur.com/ZwIWS08.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "\n",
    "To upload custom analysis functions to the DoData server, follow these simplified guidelines:\n",
    "\n",
    "- Input:\n",
    "  - Begin with a unique identifier (device_data_id, die_id, wafer_id) as the first argument.\n",
    "  - Add necessary keyword arguments for the analysis.\n",
    "\n",
    "- Output: Dictionary\n",
    "  - output: Return a simple, one-level dictionary. All values must be serializable. Avoid using numpy or pandas; convert to lists if needed.\n",
    "  - summary_plot: Provide a summary plot, either as a matplotlib figure or io.BytesIO object.\n",
    "  - attributes: Add a serializable dictionary of the analysis settings.\n",
    "  - device_data_id/die_id/wafer_id: Include the used identifier (device_data_id, die_id, wafer_id).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Device analysis\n",
    "\n",
    "You can either trigger analysis automatically by defining it in the design manifest, using the UI or using the Python DoData library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code, Image, display\n",
    "\n",
    "import doplaydo.dodata as dd\n",
    "\n",
    "display(Code(dd.config.Path.analysis_functions_device_fsr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "You can easily get a device pkey to try your device analsys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dd.get_session() as session:\n",
    "    device_data = dd.get_data_objects_by_query(\n",
    "        [\n",
    "            dd.Project.project_id == PROJECT_ID,\n",
    "            dd.attribute_filter(dd.Cell, \"radius_um\", 20),\n",
    "            dd.attribute_filter(dd.Cell, \"gap_um\", 0.2),\n",
    "        ],\n",
    "        limit=1,\n",
    "        session=session,\n",
    "    )[0]\n",
    "    device_data_pkey = device_data.pkey\n",
    "    device_data_device_id = device_data.device.device_id\n",
    "device_data_pkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = dd.api.analysis_functions.validate(\n",
    "    analysis_function_id=\"device_fsr\",\n",
    "    function_path=dd.config.Path.analysis_functions_device_fsr,\n",
    "    test_model_pkey=device_data_pkey,\n",
    "    target_model_name=\"device_data\",\n",
    "    parameters={\"height\": -0.02},\n",
    ")\n",
    "Image(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = dd.api.analysis_functions.validate_and_upload(\n",
    "    analysis_function_id=\"device_fsr\",\n",
    "    function_path=dd.config.Path.analysis_functions_device_fsr,\n",
    "    test_model_pkey=device_data.pkey,\n",
    "    target_model_name=\"device_data\",\n",
    "    parameters={\"height\": -0.02},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Trigger all analyses for all device data\n",
    "\n",
    "You have 64 dies and you will get 64 analysis, one for each device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dd.get_session() as session:\n",
    "    device_data_objects = dd.get_data_objects_by_query(\n",
    "        [\n",
    "            dd.Project.project_id == PROJECT_ID,\n",
    "            dd.attribute_filter(dd.Cell, \"gap_um\", 0.2),\n",
    "        ],\n",
    "        session=session,\n",
    "    )\n",
    "    device_data_pkeys = [d.pkey for d in device_data_objects]\n",
    "    params = [{\"height\": -0.02}] * len(device_data_objects)\n",
    "    analyses = dd.api.analysis.trigger_device_data_multi(\n",
    "        device_data_pkeys=device_data_pkeys,\n",
    "        analysis_function_id=\"device_fsr\",\n",
    "        parameters=params,\n",
    "        progress_bar=True,\n",
    "    )\n",
    "    test_die_pkey = device_data_objects[0].die.pkey\n",
    "    print(len(analyses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Die analysis\n",
    "\n",
    "You can aggregate any metric for a die analysis, for example, we had 3 different ring radius. Each of which will have a different FSR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_attributes = {\"radius_um\": 20, \"gap_um\": 0.2}\n",
    "\n",
    "response = dd.api.analysis_functions.validate(\n",
    "    analysis_function_id=\"die_aggregate\",\n",
    "    function_path=dd.config.Path.analysis_functions_die_aggregate,\n",
    "    test_model_pkey=test_die_pkey,\n",
    "    target_model_name=\"die\",\n",
    "    parameters={\n",
    "        \"device_attributes\": device_attributes,\n",
    "        \"device_analysis_function\": \"device_fsr\",\n",
    "        \"metric\": \"fsr_mean\",\n",
    "    },\n",
    ")\n",
    "Image(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_data_objects[0].die.pkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dd.get_session() as session:\n",
    "    device_data_objects = dd.get_data_objects_by_query(\n",
    "        [\n",
    "            dd.Project.project_id == PROJECT_ID,\n",
    "            dd.attribute_filter(dd.Cell, \"gap_um\", 0.2),\n",
    "        ],\n",
    "        session=session,\n",
    "    )\n",
    "    device_id = device_data_objects[0].device.device_id\n",
    "    response = dd.api.analysis_functions.validate_and_upload(\n",
    "        analysis_function_id=\"die_aggregate\",\n",
    "        function_path=dd.config.Path.analysis_functions_die_aggregate,\n",
    "        test_model_pkey=device_data_objects[0].die.pkey,\n",
    "        target_model_name=\"die\",\n",
    "        parameters={\n",
    "            \"device_attributes\": device_attributes,\n",
    "            \"device_analysis_function\": \"device_fsr\",\n",
    "            \"metric\": \"fsr_mean\",\n",
    "        },\n",
    "    )\n",
    "    wafer_pkey = device_data_objects[0].die.wafer.pkey\n",
    "    wafer_id = device_data_objects[0].die.wafer.wafer_id\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### Wafer Analysis\n",
    "\n",
    "Lets Define the Upper and Lower Spec limits for Known Good Die (KGD).\n",
    "\n",
    "Lets find a wafer pkey for this project, so that we can trigger the die analysis on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "wafer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"device_id\": device_id,\n",
    "    \"lower_spec\": 4.60,\n",
    "    \"upper_spec\": 4.75,\n",
    "    \"analysis_function_id\": \"device_fsr\",\n",
    "    \"metric\": \"fsr_mean\",\n",
    "}\n",
    "\n",
    "response = dd.api.analysis_functions.validate(\n",
    "    analysis_function_id=\"wafer_aggregate\",\n",
    "    function_path=dd.config.Path.analysis_functions_wafer_device_data_id,\n",
    "    test_model_pkey=wafer_pkey,\n",
    "    target_model_name=\"wafer\",\n",
    "    parameters=parameters,\n",
    ")\n",
    "Image(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = dd.api.analysis_functions.validate_and_upload(\n",
    "    analysis_function_id=\"wafer_aggregate\",\n",
    "    function_path=dd.config.Path.analysis_functions_wafer_device_data_id,\n",
    "    test_model_pkey=wafer_pkey,\n",
    "    target_model_name=\"wafer\",\n",
    "    parameters=parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Now that you have uploaded the wafer analysis function you can trigger the wafer analysis for all the wafers so you can store and visualize the wafermaps in the DoData website.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dd.get_session() as session:\n",
    "    device_data, df = dd.get_data_by_query(\n",
    "        [\n",
    "            dd.Project.project_id == PROJECT_ID,\n",
    "            dd.attribute_filter(dd.Cell, \"radius_um\", 20),\n",
    "            dd.attribute_filter(dd.Cell, \"gap_um\", 0.2),\n",
    "        ],\n",
    "        limit=1,\n",
    "        session=session,\n",
    "    )[0]\n",
    "    print(device_data.device.device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dd.get_session() as session:\n",
    "    device_data20, df = dd.get_data_by_query(\n",
    "        [\n",
    "            dd.Project.project_id == PROJECT_ID,\n",
    "            dd.attribute_filter(dd.Cell, \"radius_um\", 20),\n",
    "            dd.attribute_filter(dd.Cell, \"gap_um\", 0.2),\n",
    "        ],\n",
    "        limit=1,\n",
    "        session=session,\n",
    "    )[0]\n",
    "    device_data10, df = dd.get_data_by_query(\n",
    "        [\n",
    "            dd.Project.project_id == PROJECT_ID,\n",
    "            dd.attribute_filter(dd.Cell, \"radius_um\", 10),\n",
    "            dd.attribute_filter(dd.Cell, \"gap_um\", 0.2),\n",
    "        ],\n",
    "        limit=1,\n",
    "        session=session,\n",
    "    )[0]\n",
    "    device_data5, df = dd.get_data_by_query(\n",
    "        [\n",
    "            dd.Project.project_id == PROJECT_ID,\n",
    "            dd.attribute_filter(dd.Cell, \"radius_um\", 5),\n",
    "            dd.attribute_filter(dd.Cell, \"gap_um\", 0.2),\n",
    "        ],\n",
    "        limit=1,\n",
    "        session=session,\n",
    "    )[0]\n",
    "    dd20_device_id = device_data20.device.device_id\n",
    "    dd10_device_id = device_data10.device.device_id\n",
    "    dd5_device_id = device_data5.device.device_id\n",
    "    dd20_wafer_id = device_data20.die.wafer.wafer_id\n",
    "    dd10_wafer_id = device_data10.die.wafer.wafer_id\n",
    "    dd5_wafer_id = device_data5.die.wafer.wafer_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "You can trigger the device analysis for rings with 200nm gaps and 20, 10 and 5um.\n",
    "\n",
    "64 dies and 3 devices will trigger 192 device analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dd.get_session() as session:\n",
    "    device_data_objects = dd.get_data_objects_by_query(\n",
    "        [\n",
    "            dd.Project.project_id == PROJECT_ID,\n",
    "            dd.or_(\n",
    "                dd.Device.device_id == dd20_device_id,\n",
    "                dd.Device.device_id == dd10_device_id,\n",
    "                dd.Device.device_id == dd5_device_id,\n",
    "            ),\n",
    "        ],\n",
    "        limit=1,\n",
    "        session=session,\n",
    "    )\n",
    "    device_data_pkeys = [d.pkey for d in device_data_objects]\n",
    "    params = [{\"height\": -0.02}] * len(device_data_objects)\n",
    "    analyses = dd.api.analysis.trigger_device_data_multi(\n",
    "        device_data_pkeys=device_data_pkeys,\n",
    "        analysis_function_id=\"device_fsr\",\n",
    "        parameters=params,\n",
    "        progress_bar=True,\n",
    "    )\n",
    "    print(len(analyses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "wafer_set = {dd5_wafer_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5um radius rings\n",
    "for _wafer in tqdm(wafer_set):\n",
    "    r = dd.analysis.trigger_wafer(\n",
    "        project_id=PROJECT_ID,\n",
    "        wafer_id=dd5_wafer_id,\n",
    "        analysis_function_id=\"wafer_aggregate\",\n",
    "        parameters={\n",
    "            \"device_id\": dd5_device_id,\n",
    "            \"lower_spec\": 18.5,\n",
    "            \"upper_spec\": 18.7,\n",
    "            \"analysis_function_id\": \"device_fsr\",\n",
    "            \"metric\": \"fsr_mean\",\n",
    "        },\n",
    "    )\n",
    "    if r.status_code != 200:\n",
    "        raise requests.HTTPError(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10um radius rings\n",
    "for _wafer in tqdm(wafer_set):\n",
    "    r = dd.analysis.trigger_wafer(\n",
    "        project_id=PROJECT_ID,\n",
    "        wafer_id=dd10_wafer_id,\n",
    "        analysis_function_id=\"wafer_aggregate\",\n",
    "        parameters={\n",
    "            \"device_id\": dd10_device_id,\n",
    "            \"lower_spec\": 9.30,\n",
    "            \"upper_spec\": 9.40,\n",
    "            \"analysis_function_id\": \"device_fsr\",\n",
    "            \"metric\": \"fsr_mean\",\n",
    "        },\n",
    "    )\n",
    "    if r.status_code != 200:\n",
    "        raise requests.HTTPError(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20um radius rings\n",
    "for _wafer in tqdm(wafer_set):\n",
    "    r = dd.analysis.trigger_wafer(\n",
    "        project_id=PROJECT_ID,\n",
    "        wafer_id=dd20_wafer_id,\n",
    "        analysis_function_id=\"wafer_aggregate\",\n",
    "        parameters={\n",
    "            \"device_id\": dd20_device_id,\n",
    "            \"lower_spec\": 4.6,\n",
    "            \"upper_spec\": 4.8,\n",
    "            \"analysis_function_id\": \"device_fsr\",\n",
    "            \"metric\": \"fsr_mean\",\n",
    "        },\n",
    "    )\n",
    "    if r.status_code != 200:\n",
    "        raise requests.HTTPError(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = dd.analysis.get_wafer_analysis_plots(\n",
    "    project_id=PROJECT_ID,\n",
    "    wafer_id=wafer_id,\n",
    "    target_model=\"wafer\",\n",
    ")\n",
    "len(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot in plots:\n",
    "    display(plot)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "custom_cell_magics": "kql"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
